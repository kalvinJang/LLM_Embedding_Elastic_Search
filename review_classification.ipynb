{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_label.pkl', 'rb') as g:\n",
    "    training_set = pickle.load(g)\n",
    "with open('test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['label'] = training_set['label'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36.0.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO']= '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/ko-gpt-trinity-1.2B-v0.5 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/kalvin/anaconda3/envs/python3-10/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "/Users/kalvin/anaconda3/envs/python3-10/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3e213d99449d5b3e637ce686e96e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.14459311962127686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e333916b76904957b170f6601e894f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.023904554545879364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01129af89c34148bc340a6b3b210451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.05988304689526558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5af45b1c98e4783912abb4ecad717f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.028891177847981453\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# model_path = 'kakaobrain/kogpt'\n",
    "# revision = 'KoGPT6B-ryan1.5b-float16'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, revision=revision,\n",
    "#             bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]') \n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path, revision=revision,\n",
    "#             num_labels=2,  pad_token_id=tokenizer.eos_token_id, torch_dtype='auto', low_cpu_mem_usage=True).to('mps')\n",
    "# classifier = pipeline(\n",
    "#     \"sentiment-analysis\",\n",
    "#     tokenizer=tokenizer, \n",
    "#     model=model, \n",
    "#     return_all_scores=True \n",
    "# )\n",
    "\n",
    "model_path = 'skt/ko-gpt-trinity-1.2B-v0.5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2).to('mps')\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    return_all_scores=True \n",
    ")\n",
    "X_training = training_set['no_tag_review'].tolist()\n",
    "Y_training = training_set['label'].tolist()\n",
    "X_test = test_set['no_tag_review'].tolist()\n",
    "Y_test = test_set['human_label'].tolist()\n",
    "\n",
    "train_encodings = tokenizer(X_training, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
    "# 'mps'로 데이터 옮기기\n",
    "train_encodings = {key: val.to('mps') for key, val in train_encodings.items()}\n",
    "test_encodings = {key: val.to('mps') for key, val in test_encodings.items()}\n",
    "Y_training_tensor = torch.tensor(Y_training).long().to('mps')\n",
    "Y_test_tensor = torch.tensor(Y_test).long().to('mps')\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], Y_training_tensor)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "optimizer = AdamW(classifier.model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "classifier.model.train()\n",
    "for epoch in range(4):  # 4번의 epoch을 진행, 필요에 따라 변경 가능\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = classifier.model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.logits.cpu(), labels.cpu())\n",
    "        loss = loss.to('mps')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./classification_model/skt/ko-gpt-trinity-1.2B-v0.5/tokenizer_config.json',\n",
       " './classification_model/skt/ko-gpt-trinity-1.2B-v0.5/special_tokens_map.json',\n",
       " './classification_model/skt/ko-gpt-trinity-1.2B-v0.5/vocab.json',\n",
       " './classification_model/skt/ko-gpt-trinity-1.2B-v0.5/merges.txt',\n",
       " './classification_model/skt/ko-gpt-trinity-1.2B-v0.5/added_tokens.json',\n",
       " './classification_model/skt/ko-gpt-trinity-1.2B-v0.5/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델 저장\n",
    "classifier.save_pretrained(\"./classification_model/\"+ model_path+ '/')\n",
    "tokenizer.save_pretrained(\"./classification_model/\"+ model_path+ '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7742abea710b44fa929075b703048165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282511210762332\n",
      "Test Accuracy: 92.83%\n",
      "Precision: 91.00%\n",
      "Recall: 92.86%\n",
      "F1 Score: 91.92%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum().item() / len(y_true)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = (y_true * y_pred).sum().item()\n",
    "    fp = ((1 - y_true) * y_pred).sum().item()\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = (y_true * y_pred).sum().item()\n",
    "    fn = (y_true * (1 - y_pred)).sum().item()\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "classifier.model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "y_pred = []\n",
    "\n",
    "# 예측 및 성능 지표 계산을 위한 루프\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to('mps'), attention_mask.to('mps'), labels.to('mps')\n",
    "\n",
    "        outputs = classifier.model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        pred_label = [0, 1]\n",
    "        batch_pred = []\n",
    "        for j in predicted:\n",
    "            predicted_label = pred_label[j]\n",
    "            y_pred.append(predicted_label)\n",
    "            batch_pred.append(predicted_label)\n",
    "        correct_predictions += torch.eq(torch.tensor(batch_pred).to('mps'), labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "y_true = np.array(Y_test.copy())\n",
    "y_pred = np.array(y_pred)\n",
    "print(correct_predictions / total_predictions)\n",
    "print(f\"Test Accuracy: {accuracy(y_pred, y_true) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision(y_true, y_pred)* 100:.2f}%\")\n",
    "print(f\"Recall: {recall(y_true, y_pred)* 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score(y_true, y_pred)* 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./long_bads_1001.pkl', 'rb') as f:\n",
    "    real_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real = real_data['no_tag_review'].tolist()\n",
    "real_encodings = tokenizer(x_real, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
    "# 'mps'로 데이터 옮기기\n",
    "real_encodings = {key: val.to('mps') for key, val in real_encodings.items()}\n",
    "real_dataset = TensorDataset(real_encodings['input_ids'], real_encodings['attention_mask'], )\n",
    "real_loader = DataLoader(real_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548538"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83c78d29ed14ec2969bae5197bedf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.model.to('mps')\n",
    "classifier.model.eval()\n",
    "\n",
    "real_pred = []\n",
    "real_prob = []\n",
    "\n",
    "# 예측 및 성능 지표 계산을 위한 루프\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(real_loader):\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to('mps'), attention_mask.to('mps')\n",
    "\n",
    "        outputs = classifier.model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        pred_label = [0, 1]\n",
    "        for j in predicted:\n",
    "            predicted_label = pred_label[j]\n",
    "            real_pred.append(predicted_label)\n",
    "        real_prob += probs.max(dim=-1)[0].tolist()\n",
    "        \n",
    "real_data['updated_pred_label'] = real_pred\n",
    "real_data['updated_pred_score'] = real_prob\n",
    "\n",
    "with open('./long_bads_1106.pkl', 'wb') as f:\n",
    "    pickle.dump(real_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./long_bads_1106.pkl', 'rb') as f:\n",
    "    real_data = pickle.load(f)\n",
    "with open('data_0930.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377557, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[real_data['updated_pred_label']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3117031089915375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 엔진의 31.1%가 긍정인데 부정으로 잘못 보여지고 있었음\n",
    "real_data[real_data['updated_pred_label']==1].shape[0] / real_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "548533    0\n",
       "548534    0\n",
       "548535    1\n",
       "548536    1\n",
       "548537    1\n",
       "Name: updated_pred_label, Length: 548538, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data['updated_pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round((1 - 10 / 100) * 100, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
